{"paragraphs":[{"text":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.sql.functions.{abs, col}\nimport org.apache.spark.sql.SaveMode\nimport spark.implicits._\n","user":"anonymous","dateUpdated":"2020-01-13T19:12:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.sql.functions.{abs, col}\nimport org.apache.spark.sql.SaveMode\nimport spark.implicits._\n"}]},"apps":[],"jobName":"paragraph_1578942320049_-926518379","id":"20200106-182031_739474902","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:12:01+0000","dateFinished":"2020-01-13T19:12:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:112628"},{"text":"val athlete = spark.read.load(s\"s3a://strava.scratch/gbm/bay-area/athleteFeatureV0.1/featureVector\")\nathlete.printSchema\n\nval edge = spark.read.load(\"s3a://strava.scratch/gbm/bay-area/edgeFeature\")\nedge.printSchema\n\nval activityDf = spark.read.parquet(s\"s3a://strava.scratch/gbm/bay-area/edgesPerActivityTest\").filter(\"activityType == 'Run'\")\nactivityDf.printSchema\n\nval edgeMeta = spark.read.load(s\"s3a://strava.scratch/gbm/bay-area/edgeMeta\").select(\"id\", \"properties.length\")\nedgeMeta.printSchema","user":"anonymous","dateUpdated":"2020-01-13T19:06:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"athlete: org.apache.spark.sql.DataFrame = [ATHLETE_ID: decimal(38,0), features: vector ... 1 more field]\nroot\n |-- ATHLETE_ID: decimal(38,0) (nullable = true)\n |-- features: vector (nullable = true)\n |-- datestr: date (nullable = true)\n\nedge: org.apache.spark.sql.DataFrame = [edgeUID: bigint, features: vector]\nroot\n |-- edgeUID: long (nullable = true)\n |-- features: vector (nullable = true)\n\nactivityDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [activityId: bigint, athleteId: bigint ... 10 more fields]\nroot\n |-- activityId: long (nullable = true)\n |-- athleteId: long (nullable = true)\n |-- activityType: string (nullable = true)\n |-- startDateLocal: double (nullable = true)\n |-- edgeList: array (nullable = true)\n |    |-- element: long (containsNull = true)\n |-- durationList: array (nullable = true)\n |    |-- element: double (containsNull = true)\n |-- distanceList: array (nullable = true)\n |    |-- element: double (containsNull = true)\n |-- coverageList: array (nullable = true)\n |    |-- element: double (containsNull = true)\n |-- elapsedTimeSum: double (nullable = true)\n |-- elapsedTime: integer (nullable = true)\n |-- movingTime: integer (nullable = true)\n |-- key: integer (nullable = true)\n\nedgeMeta: org.apache.spark.sql.DataFrame = [id: int, length: double]\nroot\n |-- id: integer (nullable = true)\n |-- length: double (nullable = true)\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14909","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14910","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14911","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14912","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913","true/jobs/job?id=14913"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1578942320052_1865955674","id":"20200106-194155_398311135","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:06:52+0000","dateFinished":"2020-01-13T19:06:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112629"},{"text":"athlete.createOrReplaceTempView(\"athletes\")\nedge.createOrReplaceTempView(\"edges\")\nactivityDf.createOrReplaceTempView(\"activity\")\nedgeMeta.createOrReplaceTempView(\"meta\")\n","user":"anonymous","dateUpdated":"2020-01-13T19:14:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1578942320054_451565939","id":"20200106-210655_800743212","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:14:09+0000","dateFinished":"2020-01-13T19:14:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112630"},{"text":"val myQuery = \"\"\"\nwith x as (\n\n    SELECT activityId, edgeUID, athleteId\n    FROM\n    activity\n    lateral view explode(edgeList) exploded_table as edgeUID\n\n)\n\n\nselect x.activityId, x.edgeUID, x.athleteId, edges.features as edgeFeature, athletes.features as athleteFeature\n\nfrom x join edges\non edges.edgeUID = x.edgeUID\njoin athletes\non x.athleteId = athletes.ATHLETE_ID\n\n\n\"\"\"\n\nval result = spark.sql(myQuery)\n","user":"anonymous","dateUpdated":"2020-01-13T19:18:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"myQuery: String =\n\"\nwith x as (\n\n    SELECT activityId, edgeUID, athleteId\n    FROM\n    activity\n    lateral view explode(edgeList) exploded_table as edgeUID\n\n)\n\n\nselect x.activityId, x.edgeUID, x.athleteId, edges.features as edgeFeature, athletes.features as athleteFeature\n\nfrom x join edges\non edges.edgeUID = x.edgeUID\njoin athletes\non x.athleteId = athletes.ATHLETE_ID\n\n\n\"\nresult: org.apache.spark.sql.DataFrame = [activityId: bigint, edgeUID: bigint ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578942320055_588989587","id":"20200102-190835_1462885509","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:18:35+0000","dateFinished":"2020-01-13T19:18:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112631"},{"text":"// assemble vector and slice and join, then run prediction\n\nimport org.apache.spark.ml.feature.{Bucketizer, Imputer, OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorSlicer}\nimport org.apache.spark.ml.linalg.{DenseVector, Vector, Vectors}\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types.{DecimalType, DoubleType, IntegerType, LongType}\n  def assembleFeature(x: DataFrame, featureCols: Array[String]): DataFrame = {\n    val assembler = new VectorAssembler()\n      .setInputCols(featureCols)\n      .setOutputCol(\"features\")\n\n    val output = assembler.transform(x)\n    output.drop(featureCols: _*)\n  }\n \n \nval idexes = Array(0, 1, 2, 7, 5, 8, 4, 3, 71, 14, 11, 6, 17, 34, 28, 70, 13, 9, 16, 12, 214, 10, 19, 20, 27, 29, 53, 62, 74, 22, 18, 68, 26, 15, 52, 46, 23, 213, 21, 210, 72, 35, 54, 50, 56, 55, 69, 51, 30, 211, 235, 47, 38, 59, 239, 240, 64, 44, 165, 129, 200, 63, 40, 234, 37, 169, 99, 140, 45, 49, 143, 233, 58, 65, 25, 130, 164, 212, 61, 241, 105, 204, 111, 144, 48, 57, 217, 161, 178, 145, 163, 199, 60, 209, 170, 231, 207, 128, 205, 110)\n    \n\nval slicer = new VectorSlicer().setInputCol(\"features\").setOutputCol(\"slicedFeatures\")\n\nslicer.setIndices(idxes)\n \nval df1 = slicer.transform(assembleFeature(result.withColumn(\"is_best_effort\", lit(1.0)).withColumn(\"isBestEffort\", lit(1.0)), Array(\"is_best_effort\", \"edgeFeature\", \"athleteFeature\"))).drop(\"features\")\n\nval df2 = slicer.transform(assembleFeature(result.withColumn(\"is_best_effort\", lit(0.0)).withColumn(\"isBestEffort\", lit(0.0)), Array(\"is_best_effort\", \"edgeFeature\", \"athleteFeature\"))).drop(\"features\")\n\nval df3 = df1.union(df2)\ndf3.createOrReplaceTempView(\"orig\")","user":"anonymous","dateUpdated":"2020-01-13T19:18:38+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.{Bucketizer, Imputer, OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorSlicer}\nimport org.apache.spark.ml.linalg.{DenseVector, Vector, Vectors}\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types.{DecimalType, DoubleType, IntegerType, LongType}\nassembleFeature: (x: org.apache.spark.sql.DataFrame, featureCols: Array[String])org.apache.spark.sql.DataFrame\nidexes: Array[Int] = Array(0, 1, 2, 7, 5, 8, 4, 3, 71, 14, 11, 6, 17, 34, 28, 70, 13, 9, 16, 12, 214, 10, 19, 20, 27, 29, 53, 62, 74, 22, 18, 68, 26, 15, 52, 46, 23, 213, 21, 210, 72, 35, 54, 50, 56, 55, 69, 51, 30, 211, 235, 47, 38, 59, 239, 240, 64, 44, 165, 129, 200, 63, 40, 234, 37, 169, 99, 140, 45, 49, 143, 233, 58, 65, 25, 130, 164, 212, 61, 241, 105, 204, 111, 144, 48, 57, 217, 161, 178, 145, 163, 199, 60, 209, 170, 231, 207, 128, 205, 110)\nslicer: org.apache.spark.ml.feature.VectorSlicer = vectorSlicer_f39008b87c35\nres15: slicer.type = vectorSlicer_f39008b87c35\ndf1: org.apache.spark.sql.DataFrame = [activityId: bigint, edgeUID: bigint ... 3 more fields]\ndf2: org.apache.spark.sql.DataFrame = [activityId: bigint, edgeUID: bigint ... 3 more fields]\ndf3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [activityId: bigint, edgeUID: bigint ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578942320057_2124323028","id":"20200106-211036_1593689841","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:18:39+0000","dateFinished":"2020-01-13T19:18:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112632"},{"text":"val myQuery = \"\"\"\nselect orig.*, meta.length\nfrom orig join meta\non abs(orig.edgeUID) = meta.id\n\"\"\"\n\nval finalEdgeDf = assembleFeature(spark.sql(myQuery), Array(\"slicedFeatures\", \"length\"))\nfinalEdgeDf.printSchema","user":"anonymous","dateUpdated":"2020-01-13T19:18:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"myQuery: String =\n\"\nselect orig.*, meta.length\nfrom orig join meta\non abs(orig.edgeUID) = meta.id\n\"\nfinalEdgeDf: org.apache.spark.sql.DataFrame = [activityId: bigint, edgeUID: bigint ... 3 more fields]\nroot\n |-- activityId: long (nullable = true)\n |-- edgeUID: long (nullable = true)\n |-- athleteId: long (nullable = true)\n |-- isBestEffort: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1578942882184_-1693328815","id":"20200113-191442_282036082","dateCreated":"2020-01-13T19:14:42+0000","dateStarted":"2020-01-13T19:18:43+0000","dateFinished":"2020-01-13T19:18:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112633"},{"text":"val path = s\"s3a://strava.scratch/gbm/bay-area/etaModel/version0.3\"\n\nval modelPipeline = PipelineModel.load(path)\n","user":"anonymous","dateUpdated":"2020-01-13T19:19:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"path: String = s3a://strava.scratch/gbm/bay-area/etaModel/version0.3\nmodelPipeline: org.apache.spark.ml.PipelineModel = pipeline_8ca652e11928\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14914","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14915","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14916","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14917","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14918","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14919","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14920","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14921","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922","true/jobs/job?id=14922"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1578942320058_506931060","id":"20200106-214219_1369185207","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:19:29+0000","dateFinished":"2020-01-13T19:19:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:112634"},{"text":"val testResult = modelPipeline.transform(finalEdgeDf).drop(\"features\")\n\ntestResult.repartition(20).write.mode(SaveMode.Overwrite).option(\"compression\", \"gzip\").parquet(\"s3a://strava.scratch/gbm/bay-area/etaResult/version0.3/testRoutesFull\")\n","user":"anonymous","dateUpdated":"2020-01-13T19:20:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14923","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924","true/jobs/job?id=14924"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1578942320060_-1603526858","id":"20200106-214218_1622590192","dateCreated":"2020-01-13T19:05:20+0000","dateStarted":"2020-01-13T19:20:05+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112635"},{"text":"val testResult = spark.read.load(\"s3a://strava.scratch/gbm/bay-area/etaResult/version0.3/testRoutesFull\")\ntestResult.printSchema\n\ntestResult.createOrReplaceTempView(\"temp\")\n\n","user":"anonymous","dateUpdated":"2020-01-13T19:20:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"testResult: org.apache.spark.sql.DataFrame = [activityId: bigint, edgeUID: bigint ... 3 more fields]\nroot\n |-- activityId: long (nullable = true)\n |-- edgeUID: long (nullable = true)\n |-- athleteId: long (nullable = true)\n |-- isBestEffort: double (nullable = true)\n |-- ETA: double (nullable = true)\n\nedgeMeta: org.apache.spark.sql.DataFrame = [id: int, length: double]\n"}]},"apps":[],"jobName":"paragraph_1578942320062_-2139889922","id":"20200106-223725_33069531","dateCreated":"2020-01-13T19:05:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112636"},{"text":"val myQuery = \"\"\"\nwith x as (\nselect \nactivityId, isBestEffort, athleteId, sum(ETA) as routeEstimation, count(1) as numEdgeSummed, sum(meta.length) as distance\nfrom temp join meta\non abs(temp.edgeUID) = meta.id\n\ngroup by activityId, isBestEffort, athleteId\n),\n\ny as (\nselect \nactivityId, size(edgeList) as numEdge, elapsedTimeSum, elapsedTime, movingTime, elapsedTimeSum*movingTime/elapsedTime as truth\nfrom activity\n)\n\nselect x.activityId, x.isBestEffort, x.athleteId, x.routeEstimation, x.numEdgeSummed, x.distance, y.numEdge, y.elapsedTimeSum, y.elapsedTime, y.movingTime, y.truth\nfrom x join y on x.activityId = y.activityId\n\"\"\"\n\nval routeETA = spark.sql(myQuery)","user":"anonymous","dateUpdated":"2020-01-13T19:05:20+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"myQuery: String =\n\"\nwith x as (\nselect\nactivityId, isBestEffort, athleteId, sum(ETA) as routeEstimation, count(1) as numEdgeSummed, sum(meta.length) as distance\nfrom temp join meta\non abs(temp.edgeUID) = meta.id\n\ngroup by activityId, isBestEffort, athleteId\n),\n\ny as (\nselect\nactivityId, size(edgeList) as numEdge, elapsedTimeSum, elapsedTime, movingTime, elapsedTimeSum*movingTime/elapsedTime as truth\nfrom activity\n)\n\nselect x.activityId, x.isBestEffort, x.athleteId, x.routeEstimation, x.numEdgeSummed, x.distance, y.numEdge, y.elapsedTimeSum, y.elapsedTime, y.movingTime, y.truth\nfrom x join y on x.activityId = y.activityId\n\"\nrouteETA: org.apache.spark.sql.DataFrame = [activityId: bigint, isBestEffort: double ... 9 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578942320063_-982463801","id":"20200106-223723_522173194","dateCreated":"2020-01-13T19:05:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112637"},{"text":"routeETA.repartition(2).write.mode(SaveMode.Overwrite).option(\"compression\", \"gzip\").parquet(\"s3a://strava.scratch/gbm/bay-area/routeResult/version0.4\")\n","user":"anonymous","dateUpdated":"2020-01-13T19:22:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1578942320065_-1016477570","id":"20200110-000102_1385468702","dateCreated":"2020-01-13T19:05:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112638"},{"user":"anonymous","dateUpdated":"2020-01-13T19:05:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578942320066_-815915308","id":"20200107-174130_1860482675","dateCreated":"2020-01-13T19:05:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:112639"}],"name":"/lucindaz/edgeToRouteAggregationV0.4","id":"2EZSABN8S","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}